{
  "last_node_id": 24,
  "last_link_id": 38,
  "nodes": [
    {
      "id": 7,
      "type": "CLIPTextEncode",
      "pos": [
        230,
        460
      ],
      "size": {
        "0": 370,
        "1": 160
      },
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 5
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            6,
            22
          ],
          "slot_index": 0
        }
      ],
      "title": "CLIP Text Encode (Negative)",
      "properties": {
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "blurry"
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 11,
      "type": "VAELoader",
      "pos": [
        680,
        690
      ],
      "size": {
        "0": 300,
        "1": 60
      },
      "flags": {},
      "order": 0,
      "mode": 0,
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "links": [
            12,
            24
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "VAELoader"
      },
      "widgets_values": [
        "vae-ft-mse-840000-ema-pruned.safetensors"
      ]
    },
    {
      "id": 4,
      "type": "CheckpointLoaderSimple",
      "pos": [
        -120,
        380
      ],
      "size": {
        "0": 290,
        "1": 100
      },
      "flags": {},
      "order": 1,
      "mode": 0,
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            1,
            36
          ],
          "slot_index": 0
        },
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            3,
            5,
            26
          ],
          "slot_index": 1
        },
        {
          "name": "VAE",
          "type": "VAE",
          "links": [],
          "slot_index": 2
        }
      ],
      "properties": {
        "Node name for S&R": "CheckpointLoaderSimple"
      },
      "widgets_values": [
        "dreamshaper_8.safetensors"
      ]
    },
    {
      "id": 3,
      "type": "KSampler",
      "pos": [
        680,
        380
      ],
      "size": {
        "0": 300,
        "1": 262
      },
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 1
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 4
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 6
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 2
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            7
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "KSampler"
      },
      "widgets_values": [
        636250194499622,
        "fixed",
        20,
        7,
        "dpmpp_2m_sde",
        "karras",
        1
      ]
    },
    {
      "id": 20,
      "type": "PreviewImage",
      "pos": [
        1190,
        380
      ],
      "size": {
        "0": 280,
        "1": 320
      },
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 30
        }
      ],
      "properties": {
        "Node name for S&R": "PreviewImage"
      }
    },
    {
      "id": 6,
      "type": "CLIPTextEncode",
      "pos": [
        230,
        240
      ],
      "size": {
        "0": 370,
        "1": 160
      },
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 3
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            4
          ],
          "slot_index": 0
        }
      ],
      "title": "CLIP Text Encode (Positive)",
      "properties": {
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "closeup of a great warrior standing in the battlefield, smoke and flames in the background\n\ndetailed, sharp, cinematic, dramatic lighting, daylight"
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 17,
      "type": "VAEDecode",
      "pos": [
        1970,
        780
      ],
      "size": {
        "0": 140,
        "1": 50
      },
      "flags": {},
      "order": 13,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 18
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 24
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            32
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "VAEDecode"
      }
    },
    {
      "id": 5,
      "type": "EmptyLatentImage",
      "pos": [
        390,
        680
      ],
      "size": {
        "0": 210,
        "1": 110
      },
      "flags": {},
      "order": 2,
      "mode": 0,
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            2
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "EmptyLatentImage"
      },
      "widgets_values": [
        512,
        512,
        1
      ]
    },
    {
      "id": 22,
      "type": "PreviewImage",
      "pos": [
        1500,
        60
      ],
      "size": {
        "0": 620,
        "1": 640
      },
      "flags": {},
      "order": 14,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 32
        }
      ],
      "properties": {
        "Node name for S&R": "PreviewImage"
      }
    },
    {
      "id": 8,
      "type": "VAEDecode",
      "pos": [
        1030,
        380
      ],
      "size": {
        "0": 140,
        "1": 50
      },
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 7
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 12
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            30,
            35
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "VAEDecode"
      }
    },
    {
      "id": 16,
      "type": "KSampler",
      "pos": [
        1650,
        780
      ],
      "size": {
        "0": 300,
        "1": 262
      },
      "flags": {},
      "order": 12,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 37
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 25
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 22
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 31
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            18
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "KSampler"
      },
      "widgets_values": [
        1,
        "fixed",
        20,
        5,
        "dpmpp_2m_sde",
        "karras",
        1
      ]
    },
    {
      "id": 19,
      "type": "CLIPTextEncode",
      "pos": [
        1380,
        990
      ],
      "size": {
        "0": 230,
        "1": 110
      },
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 26
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            25
          ],
          "slot_index": 0
        }
      ],
      "title": "CLIP Text Encode (Positive)",
      "properties": {
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "(wearing a hat:1.2)"
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 23,
      "type": "IPAdapter",
      "pos": [
        1360,
        780
      ],
      "size": [
        250,
        170
      ],
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 36
        },
        {
          "name": "image",
          "type": "IMAGE",
          "link": 35
        },
        {
          "name": "clip_vision",
          "type": "CLIP_VISION",
          "link": 38
        },
        {
          "name": "mask",
          "type": "MASK",
          "link": null
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            37
          ],
          "shape": 3,
          "slot_index": 0
        },
        {
          "name": "CLIP_VISION_OUTPUT",
          "type": "CLIP_VISION_OUTPUT",
          "links": null,
          "shape": 3
        }
      ],
      "properties": {
        "Node name for S&R": "IPAdapter"
      },
      "widgets_values": [
        0.75,
        "ip-adapter_sd15.bin",
        "fp16"
      ]
    },
    {
      "id": 21,
      "type": "EmptyLatentImage",
      "pos": [
        1080,
        890
      ],
      "size": {
        "0": 210,
        "1": 110
      },
      "flags": {},
      "order": 3,
      "mode": 0,
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            31
          ],
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "EmptyLatentImage"
      },
      "widgets_values": [
        512,
        512,
        4
      ]
    },
    {
      "id": 24,
      "type": "CLIPVisionLoader",
      "pos": [
        1010,
        780
      ],
      "size": [
        280,
        60
      ],
      "flags": {},
      "order": 4,
      "mode": 0,
      "outputs": [
        {
          "name": "CLIP_VISION",
          "type": "CLIP_VISION",
          "links": [
            38
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPVisionLoader"
      },
      "widgets_values": [
        "IP-Adapter_sd15_pytorch_model.bin"
      ]
    }
  ],
  "links": [
    [
      1,
      4,
      0,
      3,
      0,
      "MODEL"
    ],
    [
      2,
      5,
      0,
      3,
      3,
      "LATENT"
    ],
    [
      3,
      4,
      1,
      6,
      0,
      "CLIP"
    ],
    [
      4,
      6,
      0,
      3,
      1,
      "CONDITIONING"
    ],
    [
      5,
      4,
      1,
      7,
      0,
      "CLIP"
    ],
    [
      6,
      7,
      0,
      3,
      2,
      "CONDITIONING"
    ],
    [
      7,
      3,
      0,
      8,
      0,
      "LATENT"
    ],
    [
      12,
      11,
      0,
      8,
      1,
      "VAE"
    ],
    [
      18,
      16,
      0,
      17,
      0,
      "LATENT"
    ],
    [
      22,
      7,
      0,
      16,
      2,
      "CONDITIONING"
    ],
    [
      24,
      11,
      0,
      17,
      1,
      "VAE"
    ],
    [
      25,
      19,
      0,
      16,
      1,
      "CONDITIONING"
    ],
    [
      26,
      4,
      1,
      19,
      0,
      "CLIP"
    ],
    [
      30,
      8,
      0,
      20,
      0,
      "IMAGE"
    ],
    [
      31,
      21,
      0,
      16,
      3,
      "LATENT"
    ],
    [
      32,
      17,
      0,
      22,
      0,
      "IMAGE"
    ],
    [
      35,
      8,
      0,
      23,
      1,
      "IMAGE"
    ],
    [
      36,
      4,
      0,
      23,
      0,
      "MODEL"
    ],
    [
      37,
      23,
      0,
      16,
      0,
      "MODEL"
    ],
    [
      38,
      24,
      0,
      23,
      2,
      "CLIP_VISION"
    ]
  ],
  "groups": [],
  "config": {},
  "extra": {},
  "version": 0.4
}